# Example Environment Configurations for LLM Provider Switching

## Development (OpenAI API)
# Fast iteration, best quality

LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

## Demo (Local Llama on Windows GPU)
# Cost-free, impressive for portfolio

LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://192.168.1.100:11434
OLLAMA_MODEL=llama3.1:8b

## Production - AWS (AWS Bedrock)
# Managed service, enterprise-ready

LLM_PROVIDER=bedrock
AWS_REGION=us-west-2
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

## Production - GCP (Vertex AI)
# Gemini models on Google Cloud

LLM_PROVIDER=vertexai
GCP_PROJECT_ID=your-gcp-project-id
VERTEXAI_LOCATION=us-central1
VERTEXAI_MODEL=gemini-1.5-pro

## Database
POSTGRES_URL=postgresql://user:pass@postgres:5432/iot_ops

## Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

## Redis (Caching)
REDIS_URL=redis://redis:6379/0
